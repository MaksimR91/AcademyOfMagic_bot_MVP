from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.schedulers import SchedulerAlreadyRunningError
from datetime import datetime, timedelta
import os
from logger import logger, S3TimedRotatingFileHandler, logger_s3, s3_client, BUCKET_NAME, LOG_DIR

scheduler = BackgroundScheduler()

def manual_rollover():
    for handler in logger.handlers:
        if isinstance(handler, S3TimedRotatingFileHandler):
            logger.info("üåÄ –†—É—á–Ω–æ–π –≤—ã–∑–æ–≤ doRollover()")
            handler.doRollover()
            break
    else:
        logger.warning("‚ùó –•–µ–Ω–¥–ª–µ—Ä S3TimedRotatingFileHandler –Ω–µ –Ω–∞–π–¥–µ–Ω")

def start_rollover_scheduler():
    scheduler.add_job(manual_rollover, "cron", hour=0, minute=5)
    try:
        scheduler.start()
    except SchedulerAlreadyRunningError:
        # –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —É–∂–µ –∑–∞–ø—É—â–µ–Ω ‚Äì –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≤—Ç–æ—Ä—É—é –ø–æ–ø—ã—Ç–∫—É
        pass
    logger.info("üïí –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Ä–æ—Ç–∞—Ü–∏–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∏ –∑–∞–ø—É—â–µ–Ω")

def upload_to_s3_yesterday():
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
    local_path = os.path.join(LOG_DIR, f"log.{yesterday}.log")
    s3_key = f"logs/log.{yesterday}.log"

    logger_s3.info("üöÄ –û—Ç–ª–æ–∂–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤ S3 (–∞–≤—Ç–æ)")
    if not os.path.exists(local_path):
        logger_s3.warning("‚ùó –õ–æ–≥-—Ñ–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –Ω–µ—á–µ–≥–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å")
        return

    try:
        with open(local_path, 'r', encoding='utf-8') as f:
            content = f.read()
            logger_s3.info(f"üìÑ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π (–∞–≤—Ç–æ):\n{content}")
    except Exception as e:
        logger_s3.warning(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}")

    try:
        s3_client.upload_file(local_path, BUCKET_NAME, s3_key)
        logger_s3.info(f"‚úÖ –ê–≤—Ç–æ-–∑–∞–≥—Ä—É–∑–∫–∞ —É—Å–ø–µ—à–Ω–∞: {s3_key}")

        try:
            s3_client.head_object(Bucket=BUCKET_NAME, Key=s3_key)
            logger_s3.info("üîç HEAD: —Ñ–∞–π–ª –ø–æ—è–≤–∏–ª—Å—è –≤ –±–∞–∫–µ—Ç–µ (–∞–≤—Ç–æ)")
        except s3_client.exceptions.ClientError as e:
            logger_s3.warning(f"‚ùó HEAD (–∞–≤—Ç–æ): —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –û—à–∏–±–∫–∞: {e}")

    except Exception as e:
        logger_s3.exception("üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≤—Ç–æ-–∑–∞–≥—Ä—É–∑–∫–µ –≤ S3")

def schedule_s3_upload():
    job_id = f"s3_upload_{datetime.now().strftime('%H%M%S')}"
    scheduler.add_job(
        upload_to_s3_yesterday,
        trigger='date',
        run_date=datetime.now() + timedelta(seconds=60),
        id=job_id,
        replace_existing=False
    )
    logger.info(f"‚è≥ –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≤—Ç–æ-–∑–∞–≥—Ä—É–∑–∫–∏ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É: job_id = {job_id}")

